{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45cb6d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TPMcalculator(pseudobulktable, genelengthtable, cellcounts = None, cellpops = None, blob = False, cellcountnorm = True):\n",
    "    \"\"\"\n",
    "    This function calculates the TPM and writes TPM files for ANANSE of single cell populations. \n",
    "    This can be done for the cellpopulations as well as the blob of all other cellpopulations. \n",
    "    For blob the parameter blob = True must be specified. For the blob approach the median of \n",
    "    the row values are taken after cellcount normalization unless the cellcountnorm is specified as False.\n",
    "    The input requires a pseudobulk count table, a gene length table and a cellcount table.\n",
    "    \"\"\"\n",
    "# Take the highest number of the genelengths\n",
    "    data3 = genelengthtable.groupby('ID')['LEN'].max().reset_index()\n",
    "\n",
    "# Merge the dataframes to add lengths to the IDs\n",
    "    print(\"Merging the gene lengths to the pseudobulk count dataframe\")\n",
    "    data4 = pd.merge(pseudobulktable, data3, on='ID')\n",
    "\n",
    "# Checking if cellpopulations are given\n",
    "    if cellpops == None:\n",
    "        cellpops = list(data4.columns[(data4.columns != 'ID') & (data4.columns != 'LEN')])\n",
    "    else:\n",
    "        try:\n",
    "            test = pseudobulktable[cellpops]\n",
    "        except KeyError as e:\n",
    "            raise KeyError('Your specified cell population(s) can not be found in the pseudobulk table')\n",
    "            \n",
    "# Checking if the pseudobulk table and cellcount table have equal cellpopulations\n",
    "    try:\n",
    "        test = pseudobulktable[cellpops]\n",
    "    except KeyError as e:\n",
    "        raise KeyError('Your specified cell population(s) are not equal in the pseudobulk table and the cellcount table')\n",
    "        \n",
    "# Display values not as scientific number but as normal float\n",
    "    #pd.set_option('display.float_format', lambda x: '%.30f' % x)\n",
    "\n",
    "# Exclude genes where no length is known\n",
    "    nan_value = float(\"NaN\")\n",
    "    data4.replace(\"\", nan_value, inplace=True)\n",
    "    data4.dropna(subset = [\"LEN\"], inplace=True)\n",
    "\n",
    "    if cellcountnorm == True:\n",
    "# Selecting populations >100 cell in scATAC-seq + normalizing against cell number\n",
    "        print (\"Adding the ratio for median cellnumber normalisation\")\n",
    "        cellcounts = cellcounts[cellcounts['population'].isin(cellpops)]\n",
    "        cellcounts\n",
    "\n",
    "# Determining the median of single cell populations\n",
    "        MED = cellcounts[\"number_of_cells\"].median()\n",
    "        cellcounts['ratio'] = cellcounts[\"number_of_cells\"]/MED\n",
    "\n",
    "# If cellcount is below median, then use original value or ratio\n",
    "        cellcounts.loc[cellcounts['ratio'] < 1, 'ratio'] = 1\n",
    "\n",
    "# Divide upon the ratio numpy array for each column\n",
    "        lst = cellcounts['ratio'].to_numpy()\n",
    "        data4[cellpops] = data4[cellpops].div(lst)\n",
    "# Calculating the TPM\n",
    "    print (\"Calculating TPM values for all cellpopulations\")\n",
    "    df = data4.rename(columns={'ID': 'gene', 'LEN': 'length'})\n",
    "    df.index = df['gene']\n",
    "    del df['gene']\n",
    "    nm = norm()\n",
    "    nm.tpm(df=df, gl='length')\n",
    "    \n",
    "# Get TPM normalized dataframe\n",
    "    tpm_df = nm.tpm_norm\n",
    "    tpmdata = tpm_df\n",
    "    tpmdata = tpmdata[cellpops]\n",
    "    #tpmdata = tpmdata.rename(index={0: 'ID'})\n",
    "    tpmdata.index.names = [\"ID\"]\n",
    "# subselecting the files to generate tpm value for each condition BLOB\n",
    "    if blob == True:\n",
    "        for i in tpmdata.columns:\n",
    "            print (\"writing TPM files for blob against cell population \" + i)\n",
    "            data5 = tpmdata\n",
    "            tpmdata2 = data5.loc[ : , (data5.columns != i) & (data5.columns != \"length\")]\n",
    "            tpmdata2cols = list(tpmdata2.columns)\n",
    "            tpmdata2 = tpmdata2[tpmdata2cols].median(axis=1)\n",
    "            final_df = pd.Series(tpmdata2, name=i)\n",
    "            final_df.to_csv(str(i)+\"blobnormtpm.tsv\", sep=\"\\t\", index=True)\n",
    "    else:        \n",
    "        for i in tpmdata.columns:\n",
    "            if i != \"ID\" and i != \"MIL\" and i != \"transcripts\" and i != \"length\":\n",
    "                print (\"Writing TPM files for cell population \" + i)\n",
    "                final_df = tpmdata[[i]]\n",
    "                final_df.to_csv(str(i)+\"tpm.tsv\", sep=\"\\t\", index=True)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d46a79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CPMcalculator(pseudobulktable, cellcounts = None, cellpops = None, blob = False, cellcountnorm = False, outdir = \"/\"):\n",
    "    \"\"\"\n",
    "    This function calculates the CPM and writes CPM files for ANANSE of single cell populations. \n",
    "    This can be done for the cellpopulations as well as the blob of all other cellpopulations. \n",
    "    For blob the parameter blob = True must be specified. For the blob approach the median of \n",
    "    the row values are taken after cellcount normalization unless the cellcountnorm is specified as False.\n",
    "    The input requires a pseudobulk count table and a cellcount table.\n",
    "    \"\"\"\n",
    "\n",
    "# Checking if cellpopulations are given\n",
    "    if cellpops == None:\n",
    "        cellpops = list(pseudobulktable.columns[(pseudobulktable.columns != 'ID')])\n",
    "    else:\n",
    "        try:\n",
    "            pseudobulktable = pseudobulktable[cellpops]\n",
    "        except KeyError as e:\n",
    "            raise KeyError('Your specified cell population(s) can not be found in the pseudobulk table')\n",
    "            \n",
    "# Checking if the pseudobulk table and cellcount table have equal cellpopulations\n",
    "    try:\n",
    "        test = pseudobulktable[cellpops]\n",
    "    except KeyError as e:\n",
    "        raise KeyError('Your specified cell population(s) are not equal in the pseudobulk table and the cellcount table')\n",
    "\n",
    "    #data4 = pseudobulktable\n",
    "    pseudobulktable\n",
    "    if cellcountnorm == True:\n",
    "# Selecting populations >100 cell in scATAC-seq + normalizing against cell number\n",
    "        print (\"Adding the ratio for median cellnumber normalisation\")\n",
    "        cellcounts = cellcounts[cellcounts['population'].isin(cellpops)]\n",
    "        cellcounts\n",
    "\n",
    "# Determining the median of single cell populations\n",
    "        MED = cellcounts[\"number_of_cells\"].median()\n",
    "        cellcounts['ratio'] = cellcounts[\"number_of_cells\"]/MED\n",
    "\n",
    "# If cellcount is below median, then use original value or ratio\n",
    "        cellcounts.loc[cellcounts['ratio'] < 1, 'ratio'] = 1\n",
    "\n",
    "# Divide upon the ratio numpy array for each column\n",
    "        lst = cellcounts['ratio'].to_numpy()\n",
    "        pseudobulktable[cellpops] = pseudobulktable[cellpops].div(lst)\n",
    "    \n",
    "    \n",
    "    pseudobulktable.index = pseudobulktable['ID']\n",
    "    del pseudobulktable['ID']\n",
    "    \n",
    "# Calculating the CPM\n",
    "    print (\"Calculating CPM values for all cellpopulations\")\n",
    "    df = pseudobulktable\n",
    "    nm = norm()\n",
    "    nm.cpm(df=df)\n",
    "    \n",
    "# Get TPM normalized dataframe\n",
    "    cpm_df = nm.cpm_norm\n",
    "    cpmdata = cpm_df\n",
    "    cpmdata = cpmdata[cellpops]\n",
    "    cpmdata.index.names = [\"ID\"]\n",
    "    \n",
    "# subselecting the files to generate cpm value for each condition BLOB\n",
    "    if blob == True:\n",
    "        for i in cpmdata.columns:\n",
    "            print (\"writing CPM files for blob against cell population \" + i)\n",
    "            data5 = cpmdata\n",
    "            cpmdata2 = data5.loc[ : , (data5.columns != i) & (data5.columns != \"length\")]\n",
    "            cpmdata2cols = list(cpmdata2.columns)\n",
    "            cpmdata2 = cpmdata2[cpmdata2cols].median(axis=1)\n",
    "            final_df = pd.Series(cpmdata2, name=i)\n",
    "            final_df.to_csv(outdir +\"blobnormcpm.tsv\", sep=\"\\t\", index=True)\n",
    "    else:        \n",
    "        for i in cpmdata.columns:\n",
    "            if i != \"ID\" and i != \"MIL\" and i != \"transcripts\" and i != \"length\":\n",
    "                print (\"Writing CPM files for cell population \" + i)\n",
    "                final_df = cpmdata[[i]]\n",
    "                final_df.to_csv(outdir + i +\"_cpm.tsv\", sep=\"\\t\", index=True)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc5c3908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CPM values for all cellpopulations\n",
      "Writing CPM files for cell population ESC\n",
      "Writing CPM files for cell population Cj\n",
      "Writing CPM files for cell population CSSC\n",
      "Writing CPM files for cell population LESC\n",
      "Writing CPM files for cell population CE\n",
      "Writing CPM files for cell population LSC\n",
      "Writing CPM files for cell population Mel\n",
      "Writing CPM files for cell population CF\n",
      "Writing CPM files for cell population Ves\n",
      "Writing CPM files for cell population MF\n",
      "Writing CPM files for cell population SK\n",
      "Writing CPM files for cell population IC\n",
      "Writing CPM files for cell population CDH19.\n",
      "Writing CPM files for cell population LE\n",
      "Writing CPM files for cell population EC\n",
      "Writing CPM files for cell population TSK\n"
     ]
    }
   ],
   "source": [
    "# Importing important libraries\n",
    "import pandas as pd\n",
    "from bioinfokit.analys import norm, get_data\n",
    "\n",
    "# Data and cellcounts for ESC data and shared genes in-between cornea and ESC\n",
    "data = pd.read_csv('/ceph/rimlsfnwi/data/moldevbio/zhou/jarts/data/scANANSE/RNA_ESC_cpm/20220401/cornea_ESC_pseudobulk.tsv', sep='\\t', header=0)\n",
    "\n",
    "outdir = \"/ceph/rimlsfnwi/data/moldevbio/zhou/jarts/data/scANANSE_31032022/RNA_CPM/\"\n",
    "\n",
    "CPMcalculator(data,outdir = outdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1c65c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CPM values for all cellpopulations\n",
      "Writing CPM files for cell population epi\n",
      "Writing CPM files for cell population stromal\n"
     ]
    }
   ],
   "source": [
    "# Importing important libraries\n",
    "import pandas as pd\n",
    "from bioinfokit.analys import norm, get_data\n",
    "\n",
    "# Data and cellcounts for ESC data and shared genes in-between cornea and ESC\n",
    "data = pd.read_csv('/ceph/rimlsfnwi/data/moldevbio/zhou/jarts/data/scANANSE/RNA_intra_cpm/20220421/intra_comp_pseudobulk.tsv', sep='\\t', header=0)\n",
    "\n",
    "outdir = \"/ceph/rimlsfnwi/data/moldevbio/zhou/jarts/data/scANANSE/RNA_intra_cpm/20220421/RNA_CPM/\"\n",
    "\n",
    "CPMcalculator(data,outdir = outdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd3a897c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging the gene lengths to the pseudobulk count dataframe\n",
      "Adding the ratio for median cellnumber normalisation\n",
      "Calculating TPM values for all cellpopulations\n",
      "Writing TPM files for cell population LiCo\n",
      "Writing TPM files for cell population FCVes\n",
      "Writing TPM files for cell population StCSC\n",
      "Writing TPM files for cell population MECIC\n"
     ]
    }
   ],
   "source": [
    "# Importing important libraries\n",
    "import pandas as pd\n",
    "from bioinfokit.analys import norm, get_data\n",
    "\n",
    "# Importing the data files nessesary for TPM calculation\n",
    "# Data and cellcounts for the four cells\n",
    "data = pd.read_csv('/ceph/rimlsfnwi/data/moldevbio/zhou/jarts/R/scRNA-seq/20210804/pseudobulk_4cells_TPM.tsv', sep='\\t', header=0)\n",
    "cellcounts = pd.read_csv('/ceph/rimlsfnwi/data/moldevbio/zhou/jarts/R/scRNA-seq/20210802/cellcounts_4cells.tsv', sep='\\t', header=0)\n",
    "\n",
    "# Data and cellcounts for blob\n",
    "#data = pd.read_csv('/ceph/rimlsfnwi/data/moldevbio/zhou/jarts/R/scRNA-seq/20210617/pseudobulk.tsv', sep='\\t', header=0)\n",
    "#cellcounts = pd.read_csv('/ceph/rimlsfnwi/data/moldevbio/zhou/jarts/R/scRNA-seq/20210730/cellcounts.tsv', sep='\\t', header=0)\n",
    "\n",
    "# Load in the gene lengths\n",
    "data2 = pd.read_csv('/ceph/rimlsfnwi/data/moldevbio/zhou/jarts/jupyter_notebooks/genelengths/idgl.tsv', sep='\\t', header=0)\n",
    "\n",
    "# Specify the cellpopulations you want from your dataframe\n",
    "#cellpops = ['CjS','LNPCs','CSB','CB','StC','CSSCs','MEC','LPCs']\n",
    "\n",
    "TPMcalculator(data,data2,cellcounts,blob=False,cellcountnorm=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cdfda3f",
   "metadata": {},
   "source": [
    "###############################################################################################################################\n",
    "Code for quantile normalization of the counts\n",
    "###############################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42e1c077",
   "metadata": {},
   "outputs": [],
   "source": [
    "def qquantlogcalc(joinedcovtable, sigregionstable = None, cellpops = None, outdir = None):\n",
    "    \"\"\"\n",
    "    Function that performs log transformation, q-quantile normalization and filters out significant regions. \n",
    "    The joined covtable is the output from Combine_peaks_V2 script and the sigregionstable is the output from\n",
    "    significance_calc_peaks_gimme.R. You can specify your own cell populations with the cellpops argument in a list.\n",
    "    \"\"\"\n",
    "    # Perform the logtransformation\n",
    "    numeric_df = joinedcovtable.apply(lambda x: np.log(x+1) if np.issubdtype(x.dtype, np.number) and np.number != 0 else x)\n",
    "    numeric_df\n",
    "\n",
    "    # Add the rownames for quantile normalization\n",
    "    numeric_df.index = numeric_df['loc']\n",
    "    del numeric_df[\"loc\"]\n",
    "\n",
    "    # Checking if cellpopulations are given\n",
    "    if cellpops == None:\n",
    "        cellpops = list(joinedcovtable.columns[joinedcovtable.columns != 'loc'])\n",
    "    else:\n",
    "        try:\n",
    "            test = joinedcovtable[cellpops]\n",
    "        except KeyError as e:\n",
    "            raise KeyError('Your specified cell population(s) can not be found in the joined coverage table')\n",
    "    \n",
    "    # Convert dataframe back to numeric (nessesary for the logtransformation)\n",
    "    numeric_df = numeric_df[cellpops]\n",
    "    numeric_df = numeric_df.astype(int)\n",
    "    \n",
    "    # Perform the q-quantile normalization\n",
    "    numericdf_quant = qnorm.quantile_normalize(numeric_df, ncpus=4)\n",
    "    \n",
    "    if outdir == None:\n",
    "        outdir = \"\"\n",
    "    \n",
    "    # Saving the file (not significant)\n",
    "    print(\"Writing the non-significant quantile file\")\n",
    "    numericdf_quant.to_csv(outdir +\"quantileall.tsv\", sep=\"\\t\", index=True)\n",
    "    \n",
    "    # If no significant regions have been specified\n",
    "    if sigregionstable == None:\n",
    "    # Merge the dataframes to add lengths to the IDs\n",
    "        return sigregionstable\n",
    "    \n",
    "    # If significant regions have been specified\n",
    "    print(\"Merging the significant regions and the q-quantile dataframe\")\n",
    "    sigregionstable.index = sigregionstable[0]\n",
    "    sigmerge = pd.merge(numericdf_quant, sigregionstable, left_index = True, right_index = True)\n",
    "    del sigmerge[0]\n",
    "    sigmerge.index.names = [\"loc\"]\n",
    "    \n",
    "    # Saving the file (significant)\n",
    "    print(\"Writing the significant quantile file\")\n",
    "    sigmerge.to_csv(outdir +\"quantilesig.tsv\", sep=\"\\t\", index=True)\n",
    "    return sigmerge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3512d7c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing the non-significant quantile file\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import qnorm\n",
    "\n",
    "data = pd.read_csv('/ceph/rimlsfnwi/data/moldevbio/zhou/jarts/data/scANANSE/ATAC_qquant/tmp/joinedcovtable_no_zero.tsv', sep='\\t', header=0)\n",
    "#sigregions = pd.read_csv('/ceph/rimlsfnwi/data/moldevbio/zhou/jarts/data/ATAC_bam/2022-01-18_peaks_all/tmp/sigregions.txt', sep=' ', header=None)\n",
    "#cellpops = ['CjS','LNPCs','CSB','CB','StC','CSSCs','MEC','LPCs']\n",
    "outdir = \"/ceph/rimlsfnwi/data/moldevbio/zhou/jarts/data/scANANSE/ATAC_qquant/\"\n",
    "\n",
    "qquantlogcalc(data, outdir = outdir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
